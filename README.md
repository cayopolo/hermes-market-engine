# hermes-market-engine
A real-time market data platform for learning FastAPI, PostgreSQL, WebSockets, and high-performance Python.

## Overview
Hermes Market Engine is a learning-driven project with a goal to build a small but "production-inspired" market data platform capa ble of:
- Listening to an exchange's real-time WebSocket stream
- Maintaining accurate, queryable orderbooks for multiple trading pairs simultaneously
- Computing core orderbook analytics such as spread, mid-price, imbalance, VWAP and so on
- Exposing the data through a clean FastAPI interface with autogenerated OpenAPI documentation
- Using PostgreSQL as the main storage layer
- Potentially experimenting with JIT-compiled logic (Numba) for high-speed orderbook and analytics calculations

## Quick Start

### 1. Setup Database

```bash
docker-compose up -d
```

For detailed setup instructions, see [DATABASE_SETUP.md](docs/DATABASE_SETUP.md)

### 2. Run Services

```bash
uv run hermes
```

This starts:
- **Data Collection Service**: Connects to Coinbase WebSocket, ingests level2 orderbook updates
- **Analytics Service**: Processes messages via Redis, maintains in-memory orderbooks for multiple products
- **FastAPI Server**: HTTP API listening on http://localhost:8000

Optional: control logging level with `--log-level debug|info|warning|error`

### 3. Access the API

**Interactive Documentation**:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

**Discover Available Products**:
```bash
curl http://localhost:8000/analytics/products
```

**Query Current Analytics**:
```bash
curl http://localhost:8000/analytics/current/ETH-EUR
```

**Get Orderbook Snapshot**:
```bash
curl http://localhost:8000/orderbook/snapshot/ETH-EUR?depth=5
```

### API Endpoints

All product-specific endpoints require `{product_id}` path parameter (e.g., `ETH-EUR`, `BTC-USD`, `XRP-USD`).

#### Analytics Endpoints (`/analytics`)
| Endpoint | Description |
|----------|-------------|
| `GET /analytics/products` | List all configured product IDs |
| `GET /analytics/current/{product_id}` | Full analytics snapshot (spread, midprice, best bid/ask) |
| `GET /analytics/midprice/{product_id}` | Current mid-price (average of best bid and ask) |
| `GET /analytics/spread/{product_id}` | Current bid-ask spread |
| `GET /analytics/imbalance/{product_id}` | Order book imbalance (-1 to 1, positive = more bids) |
| `GET /analytics/vamp/{product_id}` | Volume-adjusted midprice (best bid/ask only) |
| `GET /analytics/vamp_n/{product_id}?depth_percent=1.0` | VAMP with n% market depth |

#### Orderbook Endpoints (`/orderbook`)
| Endpoint | Description |
|----------|-------------|
| `GET /orderbook/snapshot/{product_id}?depth=N` | Current orderbook with top N levels (default: 10) |
| `GET /orderbook/bids/{product_id}?depth=N` | Best bid levels |
| `GET /orderbook/asks/{product_id}?depth=N` | Best ask levels |
| `GET /orderbook/depth/{product_id}` | Full orderbook depth (number of bid/ask levels) |

#### History Endpoints (`/history`)
| Endpoint | Description |
|----------|-------------|
| `GET /history/raw-events` | Query historical raw events from database by time range and product |

All endpoints provide **real-time data** with **<1ms latency** by querying the in-memory analytics engine.

---

## Project Goals & Learning Outcomes

Gained hands-on experience with:

- [x] FastAPI & async HTTP servers
- [x] PostgreSQL schema design & connection pooling
- [x] WebSockets & async IO with exponential backoff
- [x] Real-time orderbook data structures
- [x] JIT-compiled order book calculations (Numba) - **[Performance testing revealed JIT provided no benefit for streaming data](docs/JIT_PERFORMANCE_ANALYSIS.md)**
  - Synthetic benchmarks showed 20-36% speedup
  - Production testing revealed 81% **slowdown** due to data conversion overhead
  - Original Python implementation is faster for real-time analytics (<1ms latency)